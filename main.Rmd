---
title: "main"
author: "Wrzesie≈Ñ Wojciech, Grudkowski Artur"
date: "22 05 2021"
output: html_document
---

```{r setup, include=FALSE}
JOB_CORES = parallel::detectCores()
source('./src/project_setup.R')
```

```{r load_src_files}
source('./src/load_data.R')
source('./src/transform_types.R')
source('./src/show_base_stats.R')
source('./src/remove_missing_vals.R')
source('./src/add_dummy_vars.R')
source('./src/create_model_formula.R')
source('./src/divide_into_folds.R')
source('./src/model_fit.R')
source('./src/model_predict.R')
source('./src/model_evaluate.R')
source('./src/cross_validate.R')
source('./src/preprocess.R')
source('./src/destruct_formula.R')
```


# Load data
```{r}
data <- load_data()

train_base <- data$train %>% dplyr::slice(1:2000)
test_base <- data$test %>% dplyr::slice(1:500)

# train_base %>% head(5) %>% knitr::kable()
# test <- data$test
```


# Print base stats
```{r}
print(train_base)
print(test_base)
show_base_stats(train_base)
```

# Transform data
```{r}
  categorical_vars_names <- c('city', 
                              'gender', 
                              'relevent_experience', 
                              'enrolled_university',
                              'education_level',
                              'major_discipline',
                              'experience',
                              'company_size',
                              'company_type',
                              'last_new_job')

train_transformed <- train_base %>% transform_types(categorical_vars_names) %>% remove_missing_vals
test_transformed <- test_base %>% transform_types(categorical_vars_names) %>% remove_missing_vals

# Remove useless columns
train_transformed <- train_transformed %>% dplyr::select(!c("enrollee_id", "city", "company_size"))
test_transformed <- test_transformed %>% dplyr::select(!c("enrollee_id", "city", "company_size"))

summary(train_transformed)
skim(train_transformed)
print(train_transformed)
```
# Add dummy vars
```{r}
# model_vars <- c('gender', 
#                 'relevent_experience', 
#                 'education_level',
#                 'major_discipline',
#                 'experience',
#                 'company_type',
#                 'last_new_job')
# # Dropp city !!!!
# model_formula <- create_model_formula('target', model_vars)
# model_formula < as.formula('~ .')
dummy_model <- dummyVars('~ .', data=train_transformed, fullRank=TRUE)

train_dummy <- train_transformed %>% add_dummy_vars(dummy_model)
test_dummy <- test_transformed %>% add_dummy_vars(dummy_model)
print(train_dummy)
```

# Create folds for cross validation
```{r}
# Skip dummy vars for now
# train_folded <- train_dummy %>% divide_into_folds
train_folded <- train_dummy %>% divide_into_folds
print(train_folded)
``` 

# Train SVM model and predict
```{r}
independent_var_vec <- names(train_transformed)
# Remove 'target' from vector
independent_var_vec <- independent_var_vec[! independent_var_vec %in% c('target')]

model_formula <- create_model_formula('target', independent_var_vec)

cv_result <- cross_validate_fn(
  data = train_folded,
  formulas = c(model_formula),
  model_fn = svm_model_fn,
  predict_fn = model_predict,
  hyperparameters = list(
    "kernel" = c("linear", "radial"),
    "cost" = c(1, 5, 10)
  ),
  fold_cols = c(".folds"),
  type = "binomial",
  parallel = TRUE,
  verbose = TRUE
)

cv_result

```

# Train XGBoost model and predict
```{r}
independent_var_vec <- names(train_dummy)
# Remove 'target' from vector
independent_var_vec <- independent_var_vec[! independent_var_vec %in% c('target')]


model_formula <- create_model_formula('target', independent_var_vec)

res_model <- xgboost_model_fn(train_dummy, as.formula(model_formula), list(
    "nthread" = c(JOB_CORES),
    "max.depth" = c(5)
  ))

print(train_dummy)

data_test <- sparse.model.matrix(as.formula(model_formula), data = train_dummy)[, -1]
preds <- predict(object = res_model,
          newdata = data_test,
          allow.new.levels = TRUE,
          probability = TRUE)

cv_result <- cross_validate_fn(
  data = train_folded,
  formulas = c(model_formula),
  model_fn = xgboost_model_fn,
  predict_fn = xgboost_predict_fn,
  hyperparameters = list(
    "nthread" = c(JOB_CORES),
    "nround" = c(1, 4, 10),
    "max_depth" = c(1, 5, 10)
  ),
  fold_cols = c(".folds"),
  type = "binomial",
  parallel = FALSE,
  verbose = TRUE
)

cv_result

```

# Results
## Balanced Accuracy, F1, MCC, Model ID, AUC
```{r}
cv_result %>% 
  dplyr::mutate(`Model ID` = 1:nrow(cv_result)) %>% 
  dplyr::arrange(dplyr::desc(AUC)) %>% 
  select_definitions(additional_includes = c("Balanced Accuracy", "F1", "MCC", "Model ID", "AUC")) %>%
  dplyr::select(-c('Fixed', 'Dependent')) %>% 
  kable(digits = 5)
```

## Best result
```{r}
best_result <- cv_result %>% 
  head(7)

best_result
print(best_result$HParams[[1]])
print(best_result$Fixed)
print(best_result$Dependent)
```

## Confusion matrix
```{r}
plot_confusion_matrix(cv_result$`Confusion Matrix`[[1]], add_sums = TRUE)
```


## ROC
```{r}
plot(best_result$ROC[[1]]$.folds)
```

## Train the best model on the whole training dataset
```{r}
best_model <- svm_model_fn(
  train_data = train_transformed,
  formula = as.formula(paste(c(best_result$Dependent, best_result$Fixed), collapse = ' ~ ')),
  hyperparameters = best_result$HParams[[1]]
)
```

## Predict on test dataset
```{r}
predict <- model_predict(
  test_data = test_transformed[-11], 
  model = best_model
)

test_transformed[["predicted_class"]] <- predict

eval <- model_evaluate(
  test_set = test_transformed, 
  target_col = "target", 
  prediction_cols = "predicted_class"
)
```

## Plot confusion matrix
```{r}
plot_confusion_matrix(eval, add_sums = TRUE)
```

## GRADIENT BOOSTING
```{r}
# dummy_model <- dummyVars('~ .', data=train_transformed, fullRank=TRUE)

# train_dummy <- train_transformed %>% add_dummy_vars(dummy_model)
# test_dummy <- test_transformed %>% add_dummy_vars(dummy_model)

# sparse_matrix <- sparse.model.matrix(target ~ ., data = train_dummy)[,-48]
# head(sparse_matrix)
# 
# output_vector <- train_dummy$target
# 
# m <- xgboost::xgboost(
#     data = sparse_matrix,
#     label = output_vector,
#     nround = 2,
#     nthread = 2,
#     max.depth = 2,
#     eta = 1,
#     objective = "binary:logistic"
#   )

xgb_model_fn <- function(train_data, formula, hyperparameters){
  sparse_matrix <- sparse.model.matrix(formula, data = train_data)[,-48]
  output_vector <- train_data$target

  head(sparse_matrix)
  head(output_vector)

  xgboost::xgboost(
    data = sparse_matrix,
    label = output_vector,
    nround = hyperparameters[["nround"]],
    objective = hyperparameters[["objective"]]
  )
}

xgb_predict_fn <- function(test_data, model, formula, hyperparameters, train_data){
  stats::predict(
    object = model,
    newdata = test_data)
}

train_folded <- train_dummy %>% divide_into_folds

xgb_result <- cross_validate_fn(
  data = train_folded,
  formulas = c("target ~ ."),
  model_fn = xgb_model_fn,
  predict_fn = xgb_predict_fn,
  hyperparameters = list(
    "nround" = c("binary:logistic"),
    "objective" = c(2)
  ),
  fold_cols = c(".folds"),
  type = "binomial",
  parallel = TRUE,
  verbose = TRUE
)

xgb_result
# m

```

## LOGISTIC REGRESSION
```{r}
# Temporary, later move to separate scripts 

lg_model_fn <- function(train_data, formula, hyperparameters){
  stats::glm(
    formula = formula,
    data = train_data,
    family = hyperparameters[["family"]]
  )
}

lg_predict_fn <- function(test_data, model, formula, hyperparameters, train_data){
  stats::predict(
    object = model,
    newdata = test_data,
    type = "response")
}

train_folded <- train_dummy %>% divide_into_folds

lg_result <- cross_validate_fn(
  data = train_folded,
  formulas = c("target ~ ."),
  model_fn = lg_model_fn,
  predict_fn = lg_predict_fn,
  hyperparameters = list(
    "family" = c("binomial")
  ),
  fold_cols = c(".folds"),
  type = "binomial",
  parallel = TRUE,
  verbose = TRUE
)
lg_result

best_result <- lg_result %>% 
  head(1)

lg_result %>% 
  dplyr::mutate(`Model ID` = 1:nrow(lg_result)) %>% 
  dplyr::arrange(dplyr::desc(AUC)) %>% 
  select_definitions(additional_includes = c("Balanced Accuracy", "F1", "MCC", "Model ID", "AUC")) %>%
  dplyr::select(-c('Fixed', 'Dependent')) %>% 
  kable(digits = 5)

plot_confusion_matrix(lg_result$`Confusion Matrix`[[1]], add_sums = TRUE)

plot(best_result$ROC[[1]]$.folds)
```

## RANDOM FOREST
```{r}
# Temporary, later move to separate scripts 

independent_var_vec <- names(train_transformed)
# Remove 'target' from vector
independent_var_vec <- independent_var_vec[! independent_var_vec %in% c('target')]

model_formula <- create_model_formula('target', independent_var_vec)

tree_model_fn <- function(train_data, formula, hyperparameters){
  randomForest(
    formula = formula,
    data = train_data,
    ntree = hyperparameters[["ntree"]]
  )
}

tree_predict_fn <- function(test_data, model, formula, hyperparameters, train_data){
  stats::predict(
    object = model,
    newdata = test_data,
    type = "response")
}

train_folded <- train_transformed %>% divide_into_folds

tree_result <- cross_validate_fn(
  data = train_folded,
  formulas = c("target ~ ."),
  model_fn = tree_model_fn,
  predict_fn = tree_predict_fn,
  hyperparameters = list(
    "ntree" = c(250)
  ),
  fold_cols = c(".folds"),
  type = "binomial",
  parallel = TRUE,
  verbose = TRUE
)

tree_result

best_result <- tree_result %>% 
  head(1)

tree_result %>% 
  dplyr::mutate(`Model ID` = 1:nrow(tree_result)) %>% 
  dplyr::arrange(dplyr::desc(AUC)) %>% 
  select_definitions(additional_includes = c("Balanced Accuracy", "F1", "MCC", "Model ID", "AUC")) %>%
  dplyr::select(-c('Fixed', 'Dependent')) %>% 
  kable(digits = 5)

plot_confusion_matrix(tree_result$`Confusion Matrix`[[1]], add_sums = TRUE)

plot(best_result$ROC[[1]]$.folds)

```


```{r}

```